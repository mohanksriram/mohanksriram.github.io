{"componentChunkName":"component---src-templates-post-tsx","path":"/face_recognition/","webpackCompilationHash":"793e06f03e238128509f","result":{"data":{"logo":{"childImageSharp":{"fixed":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsSAAALEgHS3X78AAABFUlEQVQY023PvUrDUBTA8ZuCtoMoOLQ4dWhN14x2kEKXFkGoohQ/QBexOHRycAidKkgHHRq69APRoTjFJYODIA6+gSBYfYMmfYLE/5VT6NALP845NyeHc9UoCHZRQvonCLKKE4ZhAXYURTsYoE9dIy5iCzfUJnEdV+RF4iu6ikFH2EPxazzOcJmg4Rnn5C8ysIEOHqTe5/sT3qXOwYOtRr5/wLAqzpCTDXu4p2ETtyjgGJ/cX+se8jeU9fa4RBt5vWENpjzdkoGPcGg4RQsbOMEFmnBRRwVDHEK/yFXfvr/CoPjvZLKcdByDyzWGeajigzorGy0oOeRJiUtITe/pX1XzDk3buIMltSFR/zTtic3060X+8z8PsEUt8G3LVQAAAABJRU5ErkJggg==","width":400,"height":128,"src":"/static/2b5eaa0de166a8b5faebad4955c2200c/647de/ghost-logo.png","srcSet":"/static/2b5eaa0de166a8b5faebad4955c2200c/647de/ghost-logo.png 1x"}}},"markdownRemark":{"html":"<h2>A Web Application for Face Recognition using any camera source.</h2>\n<p>In this blog post, we will see how to create a web application for facial recognition. This application can serve as the basis for a real-time facial recognition system at your company/college. We use the latest pre-trained deep learning models. We will start by exploring the architecture of the system and as we move along, dive into the details.</p>\n<p>Here is a look at the overall setup of the system.</p>\n<p><a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/68109929ce880787990686397824dd16/09e65/face_detector.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 751px;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 22.769640479360852%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsSAAALEgHS3X78AAAA5UlEQVQY022M7VKDMBBFef93cqw4FvsOdbRFaHAghCYBytdxG7H1hztzkzt77t6o9xW910GdK3G2wRiDtQ7vTNj17Q9vxXtnqbSmro34hnAv/BIyJdFQvdBkT5yzmEkneHNk//ZOlikuzZ6hfMZ8Cs9j5npHZwsOx5Q8V5I9YPNH4RvqdCMdD0SjfsUXCe1XwlCJNyllqTGNY3Qfstvi1HblO/xZoXUtMoytoi+TcO8LuVUxEczctEzyL9xm+d395feZppGu8/Sr5mm4FkpuudcEL0/QWv8fv07X9ZxOKijLc6xzfANZSX3/KZlRQQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n    ></span>\n    <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\"\n        alt=\"Face Detector\"\n        title=\"detector\"\n        src=\"/static/68109929ce880787990686397824dd16/09e65/face_detector.png\"\n        srcset=\"/static/68109929ce880787990686397824dd16/bc34b/face_detector.png 293w,\n/static/68109929ce880787990686397824dd16/da9f0/face_detector.png 585w,\n/static/68109929ce880787990686397824dd16/09e65/face_detector.png 751w\"\n        sizes=\"(max-width: 751px) 100vw, 751px\"\n      />\n  </span>\n  </a></p>\n<ul>\n<li>React Front End: Accesses the web camera, send frames for prediction </li>\n<li>Flask Back End: Receive frames, push frames through the face recognition engine, return predictions.</li>\n<li>Face Recognition Engine: Localize faces in a frame, predict the person to whom the face belongs to. </li>\n</ul>\n<p>Let us see how the face recognition engine operates:</p>\n<p><a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/9e783b28edb226db020729dddb3fd7b0/4acde/data_flow.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 751px;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 84.02130492676432%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAARABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAECBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHvLmNCkAD/xAAUEAEAAAAAAAAAAAAAAAAAAAAw/9oACAEBAAEFAh//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAUEAEAAAAAAAAAAAAAAAAAAAAw/9oACAEBAAY/Ah//xAAZEAACAwEAAAAAAAAAAAAAAAAAARARMUH/2gAIAQEAAT8hoUcFnC4eCP/aAAwDAQACAAMAAAAQnM8A/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPxAf/8QAFREBAQAAAAAAAAAAAAAAAAAAIEH/2gAIAQIBAT8Qo//EAB4QAQACAgEFAAAAAAAAAAAAAAEAESExEEFRcZHB/9oACAEBAAE/EO63WukWGzPuFJdV5nxK5IC4B0kNHBpP/9k='); background-size: cover; display: block;\"\n    ></span>\n    <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\"\n        alt=\"Face Recognition Engine\"\n        title=\"Face Recognition Engine\"\n        src=\"/static/9e783b28edb226db020729dddb3fd7b0/4acde/data_flow.jpg\"\n        srcset=\"/static/9e783b28edb226db020729dddb3fd7b0/e33f8/data_flow.jpg 293w,\n/static/9e783b28edb226db020729dddb3fd7b0/d5ce0/data_flow.jpg 585w,\n/static/9e783b28edb226db020729dddb3fd7b0/4acde/data_flow.jpg 751w\"\n        sizes=\"(max-width: 751px) 100vw, 751px\"\n      />\n  </span>\n  </a></p>\n<h3>1. FaceDetecor:</h3>\n<ul>\n<li>Receives an image from the camera source, finds the location of the face in the image.</li>\n</ul>\n<p>There are multiple pre-trained detectors available online: <a href=\"https://github.com/ipazc/mtcnn\">mtcnn</a>, <a href=\"https://github.com/ageitgey/face_recognition\">face_recognition</a>. But for our real-time use case, we need a really fast detector. After benchmarking several detectors, I found that opencv’s <a href=\"https://github.com/opencv/opencv/tree/master/samples/dnn/face_detector\">dnn</a> face detector has an inference time that is an order of magnitude better than mtcnn, and other detectors. This network is based on SSD Framework with a resnet-10 like architecture.</p>\n<p>Here’s a look at what enters the detector and leaves the detector.</p>\n<p><a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/d39467bec93d9d78e8df4d66b4bb4c1f/6c717/hrithik_detector.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 996px;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 39.2570281124498%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAIABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAIDBf/EABQBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAYa4NoT/xAAZEAADAAMAAAAAAAAAAAAAAAABAxICERP/2gAIAQEAAQUCAd2xuF1r/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGhAAAgIDAAAAAAAAAAAAAAAAABECURMhIv/aAAgBAQAGPwKTyIlpUd2f/8QAGxAAAgMAAwAAAAAAAAAAAAAAAREAITFBcaH/2gAIAQEAAT8hAJpKFwKREud+x5ojjqf/2gAMAwEAAgADAAAAEHPP/8QAFhEAAwAAAAAAAAAAAAAAAAAAARAx/9oACAEDAQE/EDF//8QAFhEBAQEAAAAAAAAAAAAAAAAAAAEx/9oACAECAQE/EJqv/8QAGxABAQABBQAAAAAAAAAAAAAAAREAITFBUYH/2gAIAQEAAT8QUdF4MS0nm2EGaO4tLr24xJtVDOB17n//2Q=='); background-size: cover; display: block;\"\n    ></span>\n    <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\"\n        alt=\"hrithik\"\n        title=\"\"\n        src=\"/static/d39467bec93d9d78e8df4d66b4bb4c1f/6c717/hrithik_detector.jpg\"\n        srcset=\"/static/d39467bec93d9d78e8df4d66b4bb4c1f/e33f8/hrithik_detector.jpg 293w,\n/static/d39467bec93d9d78e8df4d66b4bb4c1f/d5ce0/hrithik_detector.jpg 585w,\n/static/d39467bec93d9d78e8df4d66b4bb4c1f/6c717/hrithik_detector.jpg 996w\"\n        sizes=\"(max-width: 996px) 100vw, 996px\"\n      />\n  </span>\n  </a></p>\n<p>Have a look at the FaceDetector class <a href=\"https://github.com/mohankumarSriram/face-detector-app/blob/master/services/face_detector.py\">here</a>.</p>\n<h3>2. Face Describer:</h3>\n<ul>\n<li>Receives the cropped face and converts it into a multi-dimensional embedding vector</li>\n</ul>\n<p>For our face recognition system, we have two main requirements.</p>\n<ol>\n<li>Whenever a new person needs to be added for recognition, the number of photos of the person might be limited. The system must be capable of picking up the person with a handful of examples.</li>\n<li>Any unauthorized person who enters the system must be clearly identified as a stranger.</li>\n</ol>\n<p>Traditional neural network architectures with softmax classifiers suffer from two main drawbacks:</p>\n<ol>\n<li>Whenever a new person enters the company, we need to add a new label and retrain the entire network.</li>\n<li>Fixed classifiers are incentivized to classify an unkown person into one of the already available labels with great confidence. Such strong false positives, lead to intruder detection problems.</li>\n</ol>\n<p>In order to circumvent these problems, the <a href=\"https://arxiv.org/abs/1503.03832\">facenet</a> paper presents a new approach to identity recognition. </p>\n<ol>\n<li>The network transforms the input image to a multi-dimensional embedding (128D vector). </li>\n<li>The embedding network is trained using a triplet loss. A Triplet of images: anchor, positive, and negative are chosen in such a way that the anchor and positive belong to the same class, whereas the negative belongs to a different class. The Loss function is shown in the following equation.<br />\n$ d(anchor, positve) + \\delta &#x3C; d(anchor, negative) $.<br />\nThe network is trained to minimize inter-class distances and maximize intra-class distances.</li>\n<li>For each of the labels, we can produce an average vector of the all the embedding vectors belonging to the same class. We thus obtain 128 dimensional vectors for each of our labels.</li>\n</ol>\n<p><a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/05fa07ad256317653664312febd7f6da/94eb9/pos_sim.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 1170px;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 50.64205457463884%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAACdklEQVQoz42SWUiUYRSG5yKC6CYCA7MoEpcx3DALyyU1MwWzVMRRJ01EqlEzNackF0TBJUXRygzXLKXMaFExNMJCsjTcJseNVkwi0hEZ15mn8f+l6CY68HK+j/PwXL0SrVbL0tKSIYvr+0+W16PRaJibm0On16HVLjA/P492YcFwW2Z5+e9I+I/R6/U8bGnijCKesDA55TeKqa+roaq6guKSIq6kpdLX1yuwkulvU4yOqJgYU/Nxcpxxtcqwx/gwMcrnSTUzP74LYHZeFuYWZoTJgylNjyNPEU54kB/BsiDcPZ1paX0iCgtzs9i+ZQPWpsbYmRqRFOJFcXIEZZmx9Hd38kndL4Dp6Urc3Q9w8oQ3NdmJ3MtNIfSoG05Ojuww2UZj4x1RWJCTgfFmCZY7t2Kzx4hUmRdtVbnMfnnHUE8n3R1PBfByagpSqTmubi6UpJylTHEKhewYUktTzMx209x8XxSWFWYjNdmEm+0uQnxdqc2Ioyonie7W26RG+pCfliiAyiwldk5W+PoHkhYdSa0yGn9fb+ztbfE5vo+eN89E4fWCDIw2SvC0NMLbeheVyeHEeNpwLfMcQy8aaG+qEcDqugqiziuJSS5FFiCnKEGBx2E/4pPzCZIH0t7xQBQO9L7mZulVmusraaws5+WjBu7eKkP1tstw1rGo1Qjg9NRXTkcqkMkTsHHwwsrWlQuxlwiJuIjNfj8et3aKwn/VRadbq4z4fv6qDwdHD5wOHkG61xk/3wBCg6OwtnPBwuoQbW1donBpcZGVlZXfWV0Vt251Veif3lDmtfk5o2FYpWZgUMX7kXEmxycYHlIJ/8GBYTQzswL3C/djUYwQOe84AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n    ></span>\n    <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\"\n        alt=\"pos_sim\"\n        title=\"\"\n        src=\"/static/05fa07ad256317653664312febd7f6da/913fc/pos_sim.png\"\n        srcset=\"/static/05fa07ad256317653664312febd7f6da/bc34b/pos_sim.png 293w,\n/static/05fa07ad256317653664312febd7f6da/da9f0/pos_sim.png 585w,\n/static/05fa07ad256317653664312febd7f6da/913fc/pos_sim.png 1170w,\n/static/05fa07ad256317653664312febd7f6da/94eb9/pos_sim.png 1246w\"\n        sizes=\"(max-width: 1170px) 100vw, 1170px\"\n      />\n  </span>\n  </a></p>\n<p><a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/f4852d2c3ac89c9ee32c5cffb2df24fe/30bcf/neg_sim.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 1170px;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 35.40630182421227%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsSAAALEgHS3X78AAAB5UlEQVQoz4WQTWjScRjHPQQbQTGonUblKIgirFOHLkGLOgQddiopQVZEji4xNrK3QyzYjlFrzMh0Ks6aLY2VrlajTNYUX2ibmL05Bi3Ll03n8u///+mHUtceeHjge/h8v99HxX9Gqsrk83nKa2tIUvWfXhX635WVulapVFAF3kwx6nLgcbvwPXUzOT5G4OU4U34v0eBr0ql5ZFlGkQVMrvAxmSASCbGUWSRXyFAs/iKbSZNKxFAEWKXXtrO5UYW6eT3bmxvoOdHGoLEDc38Xn2ZDLCTjSMIZRRJxS/xcSpP8/IERl5mLnacIhyZIxl7gcw+KBiKhQX9SgBrZvXUTBzStXNEewTN0k9KPWYL+R3jsJuGsoKwWUVaylEuFWj3T7T4Oa7YQj7/j+7cY05MP68CuTh0a9Uba9qk5ffwQ7r5uhq5dwD8yQK+hHaNBVwOMDtuZCwYoZDMsV1ax3Ollf2sTRuMlkTxH5mtM/LOKque8lpYNKo7tbeGoSGjp1qE/uIdbV8+xEPfxzGmqAW8YjTjvDhCfec+ZjrNsa2oQu45dO3bSf/0yy4vJOnD67Ssclnv4x1w8cdqYmfDw2GEhEQkKjIL0u1QDRsNh5mNRviRT2K3DPLhvxma1YRX3uddLeSVXe80fBc61Ae7tKOwAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n    ></span>\n    <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\"\n        alt=\"neg_sim\"\n        title=\"\"\n        src=\"/static/f4852d2c3ac89c9ee32c5cffb2df24fe/913fc/neg_sim.png\"\n        srcset=\"/static/f4852d2c3ac89c9ee32c5cffb2df24fe/bc34b/neg_sim.png 293w,\n/static/f4852d2c3ac89c9ee32c5cffb2df24fe/da9f0/neg_sim.png 585w,\n/static/f4852d2c3ac89c9ee32c5cffb2df24fe/913fc/neg_sim.png 1170w,\n/static/f4852d2c3ac89c9ee32c5cffb2df24fe/30bcf/neg_sim.png 1206w\"\n        sizes=\"(max-width: 1170px) 100vw, 1170px\"\n      />\n  </span>\n  </a></p>\n<p>Have a look at the FaceDescriber class <a href=\"https://github.com/mohankumarSriram/face-detector-app/blob/master/services/face_describer.py\">here</a></p>\n<h3>Face Verifier:</h3>\n<ul>\n<li>\n<p>Receives the embedding vector, compares with existing vectors to produce the most similar class</p>\n</li>\n<li>\n<p>During the time of inference, we calculate the similarity measure between the stored embedding vectors for each of the classes and the new embedding.</p>\n</li>\n<li>\n<p>We use these similarity distances to assign the most similar (min-distance) class.</p>\n</li>\n</ul>\n<p>You can find the Faceverifier class <a href=\"https://github.com/mohankumarSriram/face-detector-app\">here</a></p>\n<p>Here’s a look at the entire application!</p>\n<p><img src=\"/final_demo-599bcbadbf340b863d8f6375a069ba4d.gif\" alt=\"demo\"></p>\n<h3>Github repo: <a href=\"https://github.com/mohankumarSriram/face-detector-app\">https://github.com/mohankumarSriram/face-detector-app</a></h3>\n<h3>Conclusion</h3>\n<p>In this blog, you have seen how to build a face recognition app using web camera. Please contact me if you need help setting up the app for an IP camera or any other source. Don’t forget to fork the repo and give it a star! If you have any feature requests, feel free to create a new issue on the repo.</p>\n<p>I currently provide full stack machine learning and deep learning solutions, you can reach me at mohankumarsriram7@gmail.com</p>\n<h3>References</h3>\n<ol>\n<li>Florian Schroff, Dmitry Kalenichenko, James Philbin. <a href=\"https://arxiv.org/abs/1503.03832\">“FaceNet: A Unified Embedding for Face Recognition and Clustering.”</a></li>\n<li><a href=\"https://machinelearningmastery.com/how-to-develop-a-face-recognition-system-using-facenet-in-keras-and-an-svm-classifier/\">Facenet with SVM</a></li>\n<li><a href=\"https://github.com/AIInAi/tf-insightface\">Server Structure</a></li>\n</ol>","htmlAst":{"type":"root","children":[{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"A Web Application for Face Recognition using any camera source."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"In this blog post, we will see how to create a web application for facial recognition. This application can serve as the basis for a real-time facial recognition system at your company/college. We use the latest pre-trained deep learning models. We will start by exploring the architecture of the system and as we move along, dive into the details."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Here is a look at the overall setup of the system."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"a","properties":{"className":["gatsby-resp-image-link"],"href":"/static/68109929ce880787990686397824dd16/09e65/face_detector.png","style":"display: block","target":"_blank","rel":["noopener"]},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 751px;"},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 22.769640479360852%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsSAAALEgHS3X78AAAA5UlEQVQY022M7VKDMBBFef93cqw4FvsOdbRFaHAghCYBytdxG7H1hztzkzt77t6o9xW910GdK3G2wRiDtQ7vTNj17Q9vxXtnqbSmro34hnAv/BIyJdFQvdBkT5yzmEkneHNk//ZOlikuzZ6hfMZ8Cs9j5npHZwsOx5Q8V5I9YPNH4RvqdCMdD0SjfsUXCe1XwlCJNyllqTGNY3Qfstvi1HblO/xZoXUtMoytoi+TcO8LuVUxEczctEzyL9xm+d395feZppGu8/Sr5mm4FkpuudcEL0/QWv8fv07X9ZxOKijLc6xzfANZSX3/KZlRQQAAAABJRU5ErkJggg=='); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n    "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;","alt":"Face Detector","title":"detector","src":"/static/68109929ce880787990686397824dd16/09e65/face_detector.png","srcSet":["/static/68109929ce880787990686397824dd16/bc34b/face_detector.png 293w","/static/68109929ce880787990686397824dd16/da9f0/face_detector.png 585w","/static/68109929ce880787990686397824dd16/09e65/face_detector.png 751w"],"sizes":["(max-width:","751px)","100vw,","751px"]},"children":[]},{"type":"text","value":"\n  "}]},{"type":"text","value":"\n  "}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"React Front End: Accesses the web camera, send frames for prediction "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Flask Back End: Receive frames, push frames through the face recognition engine, return predictions."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Face Recognition Engine: Localize faces in a frame, predict the person to whom the face belongs to. "}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Let us see how the face recognition engine operates:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"a","properties":{"className":["gatsby-resp-image-link"],"href":"/static/9e783b28edb226db020729dddb3fd7b0/4acde/data_flow.jpg","style":"display: block","target":"_blank","rel":["noopener"]},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 751px;"},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 84.02130492676432%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAARABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAECBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHvLmNCkAD/xAAUEAEAAAAAAAAAAAAAAAAAAAAw/9oACAEBAAEFAh//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAUEAEAAAAAAAAAAAAAAAAAAAAw/9oACAEBAAY/Ah//xAAZEAACAwEAAAAAAAAAAAAAAAAAARARMUH/2gAIAQEAAT8hoUcFnC4eCP/aAAwDAQACAAMAAAAQnM8A/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPxAf/8QAFREBAQAAAAAAAAAAAAAAAAAAIEH/2gAIAQIBAT8Qo//EAB4QAQACAgEFAAAAAAAAAAAAAAEAESExEEFRcZHB/9oACAEBAAE/EO63WukWGzPuFJdV5nxK5IC4B0kNHBpP/9k='); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n    "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;","alt":"Face Recognition Engine","title":"Face Recognition Engine","src":"/static/9e783b28edb226db020729dddb3fd7b0/4acde/data_flow.jpg","srcSet":["/static/9e783b28edb226db020729dddb3fd7b0/e33f8/data_flow.jpg 293w","/static/9e783b28edb226db020729dddb3fd7b0/d5ce0/data_flow.jpg 585w","/static/9e783b28edb226db020729dddb3fd7b0/4acde/data_flow.jpg 751w"],"sizes":["(max-width:","751px)","100vw,","751px"]},"children":[]},{"type":"text","value":"\n  "}]},{"type":"text","value":"\n  "}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"1. FaceDetecor:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Receives an image from the camera source, finds the location of the face in the image."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"There are multiple pre-trained detectors available online: "},{"type":"element","tagName":"a","properties":{"href":"https://github.com/ipazc/mtcnn"},"children":[{"type":"text","value":"mtcnn"}]},{"type":"text","value":", "},{"type":"element","tagName":"a","properties":{"href":"https://github.com/ageitgey/face_recognition"},"children":[{"type":"text","value":"face_recognition"}]},{"type":"text","value":". But for our real-time use case, we need a really fast detector. After benchmarking several detectors, I found that opencv’s "},{"type":"element","tagName":"a","properties":{"href":"https://github.com/opencv/opencv/tree/master/samples/dnn/face_detector"},"children":[{"type":"text","value":"dnn"}]},{"type":"text","value":" face detector has an inference time that is an order of magnitude better than mtcnn, and other detectors. This network is based on SSD Framework with a resnet-10 like architecture."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Here’s a look at what enters the detector and leaves the detector."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"a","properties":{"className":["gatsby-resp-image-link"],"href":"/static/d39467bec93d9d78e8df4d66b4bb4c1f/6c717/hrithik_detector.jpg","style":"display: block","target":"_blank","rel":["noopener"]},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 996px;"},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 39.2570281124498%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAIABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAIDBf/EABQBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAYa4NoT/xAAZEAADAAMAAAAAAAAAAAAAAAABAxICERP/2gAIAQEAAQUCAd2xuF1r/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGhAAAgIDAAAAAAAAAAAAAAAAABECURMhIv/aAAgBAQAGPwKTyIlpUd2f/8QAGxAAAgMAAwAAAAAAAAAAAAAAAREAITFBcaH/2gAIAQEAAT8hAJpKFwKREud+x5ojjqf/2gAMAwEAAgADAAAAEHPP/8QAFhEAAwAAAAAAAAAAAAAAAAAAARAx/9oACAEDAQE/EDF//8QAFhEBAQEAAAAAAAAAAAAAAAAAAAEx/9oACAECAQE/EJqv/8QAGxABAQABBQAAAAAAAAAAAAAAAREAITFBUYH/2gAIAQEAAT8QUdF4MS0nm2EGaO4tLr24xJtVDOB17n//2Q=='); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n    "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;","alt":"hrithik","title":"","src":"/static/d39467bec93d9d78e8df4d66b4bb4c1f/6c717/hrithik_detector.jpg","srcSet":["/static/d39467bec93d9d78e8df4d66b4bb4c1f/e33f8/hrithik_detector.jpg 293w","/static/d39467bec93d9d78e8df4d66b4bb4c1f/d5ce0/hrithik_detector.jpg 585w","/static/d39467bec93d9d78e8df4d66b4bb4c1f/6c717/hrithik_detector.jpg 996w"],"sizes":["(max-width:","996px)","100vw,","996px"]},"children":[]},{"type":"text","value":"\n  "}]},{"type":"text","value":"\n  "}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Have a look at the FaceDetector class "},{"type":"element","tagName":"a","properties":{"href":"https://github.com/mohankumarSriram/face-detector-app/blob/master/services/face_detector.py"},"children":[{"type":"text","value":"here"}]},{"type":"text","value":"."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"2. Face Describer:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Receives the cropped face and converts it into a multi-dimensional embedding vector"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"For our face recognition system, we have two main requirements."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ol","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Whenever a new person needs to be added for recognition, the number of photos of the person might be limited. The system must be capable of picking up the person with a handful of examples."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Any unauthorized person who enters the system must be clearly identified as a stranger."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Traditional neural network architectures with softmax classifiers suffer from two main drawbacks:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ol","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Whenever a new person enters the company, we need to add a new label and retrain the entire network."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Fixed classifiers are incentivized to classify an unkown person into one of the already available labels with great confidence. Such strong false positives, lead to intruder detection problems."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"In order to circumvent these problems, the "},{"type":"element","tagName":"a","properties":{"href":"https://arxiv.org/abs/1503.03832"},"children":[{"type":"text","value":"facenet"}]},{"type":"text","value":" paper presents a new approach to identity recognition. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ol","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"The network transforms the input image to a multi-dimensional embedding (128D vector). "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"The embedding network is trained using a triplet loss. A Triplet of images: anchor, positive, and negative are chosen in such a way that the anchor and positive belong to the same class, whereas the negative belongs to a different class. The Loss function is shown in the following equation."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\n$ d(anchor, positve) + \\delta < d(anchor, negative) $."},{"type":"element","tagName":"br","properties":{},"children":[]},{"type":"text","value":"\nThe network is trained to minimize inter-class distances and maximize intra-class distances."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"For each of the labels, we can produce an average vector of the all the embedding vectors belonging to the same class. We thus obtain 128 dimensional vectors for each of our labels."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"a","properties":{"className":["gatsby-resp-image-link"],"href":"/static/05fa07ad256317653664312febd7f6da/94eb9/pos_sim.png","style":"display: block","target":"_blank","rel":["noopener"]},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 1170px;"},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 50.64205457463884%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAACdklEQVQoz42SWUiUYRSG5yKC6CYCA7MoEpcx3DALyyU1MwWzVMRRJ01EqlEzNackF0TBJUXRygzXLKXMaFExNMJCsjTcJseNVkwi0hEZ15mn8f+l6CY68HK+j/PwXL0SrVbL0tKSIYvr+0+W16PRaJibm0On16HVLjA/P492YcFwW2Z5+e9I+I/R6/U8bGnijCKesDA55TeKqa+roaq6guKSIq6kpdLX1yuwkulvU4yOqJgYU/Nxcpxxtcqwx/gwMcrnSTUzP74LYHZeFuYWZoTJgylNjyNPEU54kB/BsiDcPZ1paX0iCgtzs9i+ZQPWpsbYmRqRFOJFcXIEZZmx9Hd38kndL4Dp6Urc3Q9w8oQ3NdmJ3MtNIfSoG05Ojuww2UZj4x1RWJCTgfFmCZY7t2Kzx4hUmRdtVbnMfnnHUE8n3R1PBfByagpSqTmubi6UpJylTHEKhewYUktTzMx209x8XxSWFWYjNdmEm+0uQnxdqc2Ioyonie7W26RG+pCfliiAyiwldk5W+PoHkhYdSa0yGn9fb+ztbfE5vo+eN89E4fWCDIw2SvC0NMLbeheVyeHEeNpwLfMcQy8aaG+qEcDqugqiziuJSS5FFiCnKEGBx2E/4pPzCZIH0t7xQBQO9L7mZulVmusraaws5+WjBu7eKkP1tstw1rGo1Qjg9NRXTkcqkMkTsHHwwsrWlQuxlwiJuIjNfj8et3aKwn/VRadbq4z4fv6qDwdHD5wOHkG61xk/3wBCg6OwtnPBwuoQbW1donBpcZGVlZXfWV0Vt251Veif3lDmtfk5o2FYpWZgUMX7kXEmxycYHlIJ/8GBYTQzswL3C/djUYwQOe84AAAAAElFTkSuQmCC'); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n    "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;","alt":"pos_sim","title":"","src":"/static/05fa07ad256317653664312febd7f6da/913fc/pos_sim.png","srcSet":["/static/05fa07ad256317653664312febd7f6da/bc34b/pos_sim.png 293w","/static/05fa07ad256317653664312febd7f6da/da9f0/pos_sim.png 585w","/static/05fa07ad256317653664312febd7f6da/913fc/pos_sim.png 1170w","/static/05fa07ad256317653664312febd7f6da/94eb9/pos_sim.png 1246w"],"sizes":["(max-width:","1170px)","100vw,","1170px"]},"children":[]},{"type":"text","value":"\n  "}]},{"type":"text","value":"\n  "}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"a","properties":{"className":["gatsby-resp-image-link"],"href":"/static/f4852d2c3ac89c9ee32c5cffb2df24fe/30bcf/neg_sim.png","style":"display: block","target":"_blank","rel":["noopener"]},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 1170px;"},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 35.40630182421227%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsSAAALEgHS3X78AAAB5UlEQVQoz4WQTWjScRjHPQQbQTGonUblKIgirFOHLkGLOgQddiopQVZEji4xNrK3QyzYjlFrzMh0Ks6aLY2VrlajTNYUX2ibmL05Bi3Ll03n8u///+mHUtceeHjge/h8v99HxX9Gqsrk83nKa2tIUvWfXhX635WVulapVFAF3kwx6nLgcbvwPXUzOT5G4OU4U34v0eBr0ql5ZFlGkQVMrvAxmSASCbGUWSRXyFAs/iKbSZNKxFAEWKXXtrO5UYW6eT3bmxvoOdHGoLEDc38Xn2ZDLCTjSMIZRRJxS/xcSpP8/IERl5mLnacIhyZIxl7gcw+KBiKhQX9SgBrZvXUTBzStXNEewTN0k9KPWYL+R3jsJuGsoKwWUVaylEuFWj3T7T4Oa7YQj7/j+7cY05MP68CuTh0a9Uba9qk5ffwQ7r5uhq5dwD8yQK+hHaNBVwOMDtuZCwYoZDMsV1ax3Ollf2sTRuMlkTxH5mtM/LOKque8lpYNKo7tbeGoSGjp1qE/uIdbV8+xEPfxzGmqAW8YjTjvDhCfec+ZjrNsa2oQu45dO3bSf/0yy4vJOnD67Ssclnv4x1w8cdqYmfDw2GEhEQkKjIL0u1QDRsNh5mNRviRT2K3DPLhvxma1YRX3uddLeSVXe80fBc61Ae7tKOwAAAAASUVORK5CYII='); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n    "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;","alt":"neg_sim","title":"","src":"/static/f4852d2c3ac89c9ee32c5cffb2df24fe/913fc/neg_sim.png","srcSet":["/static/f4852d2c3ac89c9ee32c5cffb2df24fe/bc34b/neg_sim.png 293w","/static/f4852d2c3ac89c9ee32c5cffb2df24fe/da9f0/neg_sim.png 585w","/static/f4852d2c3ac89c9ee32c5cffb2df24fe/913fc/neg_sim.png 1170w","/static/f4852d2c3ac89c9ee32c5cffb2df24fe/30bcf/neg_sim.png 1206w"],"sizes":["(max-width:","1170px)","100vw,","1170px"]},"children":[]},{"type":"text","value":"\n  "}]},{"type":"text","value":"\n  "}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Have a look at the FaceDescriber class "},{"type":"element","tagName":"a","properties":{"href":"https://github.com/mohankumarSriram/face-detector-app/blob/master/services/face_describer.py"},"children":[{"type":"text","value":"here"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Face Verifier:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Receives the embedding vector, compares with existing vectors to produce the most similar class"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"During the time of inference, we calculate the similarity measure between the stored embedding vectors for each of the classes and the new embedding."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"We use these similarity distances to assign the most similar (min-distance) class."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"You can find the Faceverifier class "},{"type":"element","tagName":"a","properties":{"href":"https://github.com/mohankumarSriram/face-detector-app"},"children":[{"type":"text","value":"here"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Here’s a look at the entire application!"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"img","properties":{"src":"/final_demo-599bcbadbf340b863d8f6375a069ba4d.gif","alt":"demo"},"children":[]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Github repo: "},{"type":"element","tagName":"a","properties":{"href":"https://github.com/mohankumarSriram/face-detector-app"},"children":[{"type":"text","value":"https://github.com/mohankumarSriram/face-detector-app"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Conclusion"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"In this blog, you have seen how to build a face recognition app using web camera. Please contact me if you need help setting up the app for an IP camera or any other source. Don’t forget to fork the repo and give it a star! If you have any feature requests, feel free to create a new issue on the repo."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"I currently provide full stack machine learning and deep learning solutions, you can reach me at mohankumarsriram7@gmail.com"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"References"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ol","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Florian Schroff, Dmitry Kalenichenko, James Philbin. "},{"type":"element","tagName":"a","properties":{"href":"https://arxiv.org/abs/1503.03832"},"children":[{"type":"text","value":"“FaceNet: A Unified Embedding for Face Recognition and Clustering.”"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://machinelearningmastery.com/how-to-develop-a-face-recognition-system-using-facenet-in-keras-and-an-svm-classifier/"},"children":[{"type":"text","value":"Facenet with SVM"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://github.com/AIInAi/tf-insightface"},"children":[{"type":"text","value":"Server Structure"}]}]},{"type":"text","value":"\n"}]}],"data":{"quirksMode":false}},"excerpt":"A Web Application for Face Recognition using any camera source.In this blog post, we will see how to create a web application for facial…","timeToRead":4,"frontmatter":{"title":"Face Recognition","userDate":"26 July 2019","date":"2019-07-26T10:00:00.000Z","tags":["Deep Learning","Application"],"image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAIABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAIDBf/EABQBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAYa4NoT/xAAZEAADAAMAAAAAAAAAAAAAAAABAxICERP/2gAIAQEAAQUCAd2xuF1r/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGhAAAgIDAAAAAAAAAAAAAAAAABECURMhIv/aAAgBAQAGPwKTyIlpUd2f/8QAGxAAAgMAAwAAAAAAAAAAAAAAAREAITFBcaH/2gAIAQEAAT8hAJpKFwKREud+x5ojjqf/2gAMAwEAAgADAAAAEHPP/8QAFhEAAwAAAAAAAAAAAAAAAAAAARAx/9oACAEDAQE/EDF//8QAFhEBAQEAAAAAAAAAAAAAAAAAAAEx/9oACAECAQE/EJqv/8QAGxABAQABBQAAAAAAAAAAAAAAAREAITFBUYH/2gAIAQEAAT8QUdF4MS0nm2EGaO4tLr24xJtVDOB17n//2Q==","aspectRatio":2.547314578005115,"src":"/static/d39467bec93d9d78e8df4d66b4bb4c1f/4b846/hrithik_detector.jpg","srcSet":"/static/d39467bec93d9d78e8df4d66b4bb4c1f/f8f18/hrithik_detector.jpg 930w,\n/static/d39467bec93d9d78e8df4d66b4bb4c1f/4b846/hrithik_detector.jpg 996w","sizes":"(max-width: 996px) 100vw, 996px"}}},"author":{"id":"Mohankumar Sriram","bio":null,"avatar":{"children":[{"__typename":"ImageSharp","fixed":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAABQABA//EABUBAQEAAAAAAAAAAAAAAAAAAAAC/9oADAMBAAIQAxAAAAFnRe00pER//8QAGhABAAIDAQAAAAAAAAAAAAAAAQACAxESIv/aAAgBAQABBQLomydEyFjEHlbT/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGRAAAwADAAAAAAAAAAAAAAAAAAExAhAR/9oACAEBAAY/AqXTYuZMp//EABsQAQACAgMAAAAAAAAAAAAAAAEAIRFhMUGh/9oACAEBAAE/IUxUATUmwjFXNUMYwSjnuBb8T//aAAwDAQACAAMAAAAQUM//xAAXEQADAQAAAAAAAAAAAAAAAAAAARFR/9oACAEDAQE/EFcK8P/EABYRAQEBAAAAAAAAAAAAAAAAABEAAf/aAAgBAgEBPxAwYy//xAAbEAACAwADAAAAAAAAAAAAAAABEQAhMWFx8f/aAAgBAQABPxAHUGSTkpdHc9aWwRNF4Y++dZ4iE08hP//Z","width":400,"height":300,"src":"/static/749c8ea9c24955061d20099f9acd71aa/f4032/mohan.jpg","srcSet":"/static/749c8ea9c24955061d20099f9acd71aa/f4032/mohan.jpg 1x,\n/static/749c8ea9c24955061d20099f9acd71aa/9429d/mohan.jpg 1.5x,\n/static/749c8ea9c24955061d20099f9acd71aa/67481/mohan.jpg 2x"}}]}}}},"relatedPosts":{"totalCount":1,"edges":[{"node":{"id":"d2206488-9883-59ac-9818-4553678ad7ac","timeToRead":4,"excerpt":"A Web Application for Face Recognition using any camera source.In this blog post, we will see how to create a web application for facial…","frontmatter":{"title":"Face Recognition"},"fields":{"slug":"/face_recognition/"}}}]}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/face_recognition/","prev":{"excerpt":"Welcome to this first post on meta learning! This post assumes that the reader is already familiar with the basic neural network…","timeToRead":3,"frontmatter":{"title":"Model-Agnostic Meta-Learning","tags":["Meta Learning","Theory"],"date":"2019-06-16T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"fluid":{"aspectRatio":5,"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAEABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAIF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB2QWD/8QAFxAAAwEAAAAAAAAAAAAAAAAAAAIyQf/aAAgBAQABBQI1J//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABUQAQEAAAAAAAAAAAAAAAAAAAEQ/9oACAEBAAY/Am//xAAZEAEAAwEBAAAAAAAAAAAAAAABABExIWH/2gAIAQEAAT8hcFuzU+VBXE//2gAMAwEAAgADAAAAEIAP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGRABAQEBAQEAAAAAAAAAAAAAAREhADFR/9oACAEBAAE/EKcYlo6caS36M84ABN3be//Z","sizes":"(max-width: 1000px) 100vw, 1000px","src":"/static/cd030ee7e4e0c904d12eb69dfedd0e19/2f7e7/learn-to-learn.jpg","srcSet":"/static/cd030ee7e4e0c904d12eb69dfedd0e19/f8f18/learn-to-learn.jpg 930w,\n/static/cd030ee7e4e0c904d12eb69dfedd0e19/2f7e7/learn-to-learn.jpg 1000w"}}},"author":{"id":"Mohankumar Sriram","bio":null,"avatar":{"children":[{"fixed":{"src":"/static/749c8ea9c24955061d20099f9acd71aa/f4032/mohan.jpg"}}]}}},"fields":{"layout":"","slug":"/maml/"}},"next":null,"primaryTag":"Deep Learning"}}}